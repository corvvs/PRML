長くなってきたので項を改める。

### 1.2.5 曲線フィッティング再訪

式(1.60)

- $\mathrm{w}$: 「平均曲線」のパラメータベクトル
- $\beta$: 逆分散($1/\sigma^2$?)
- $y(x,\mathrm{w})$: 「平均曲線」

$$
p(t | x, \mathrm{w}, \beta) =  \mathcal{N}(t | y(x,\mathrm{w}), \beta)
$$

「パラメータ$\mathrm{w},\beta$のもとでデータ$x$が得られた時の目標変数$t$の実現確率」

多数の$(x,t)$の組$(\mathrm{x},\mathrm{t})$についての確率をまとめて書くと

$$
p(\mathrm{t} | \mathrm{x}, \mathrm{w}, \beta) =  \prod_{n}\mathcal{N}(t_n | y(x_n,\mathrm{w}), \beta)
$$

#### 最尤推定

対数尤度は

$$
\ln \prod_{n}\mathcal{N}(t_n | y(x_n,\mathrm{w}), \beta) = 
\sum_{n} \ln \left( \sqrt{\frac{\beta}{{2\pi}}} \exp\left( -\frac{\beta}{2}(t_n - y(x_n,\mathrm{w}))^2 \right)\right) \\
= \frac{N}{2}\ln\frac{\beta}{2\pi} - \frac{\beta}{2} \sum_{n} \left(t_n - y(x_n, \mathrm{w})\right)^2.
$$

これの最大値を与えるパラメータ(=総和$\sum_{n} \left(t_n - y(x_n, \mathrm{w})\right)^2$の最小値を与えるパラメータ)$\mathrm{w}$を$\mathrm{w}_{\mathrm{ML}}$と書くことにする(関数形から、これは$\beta$の影響を受けない)。

最大値を与える$\beta$については、対数尤度を$\beta$で偏微分すると

$$
\frac{N}{\beta} - \sum_n\left(t_n - y(x_n, \mathrm{w})\right)^2 = 0\\
\rightarrow \beta = \frac{N}{\sum_n\left(t_n - y(x_n, \mathrm{w})\right)^2}
$$

$\mathrm{w}$については、明らかに$=\mathrm{w}_{\mathrm{ML}}$の時に最大となるので、

$$
\beta_{\mathrm{ML}} = \frac{N}{\sum_n\left(t_n - y(x_n, \mathrm{w})_{\mathrm{ML}}\right)^2}
$$

#### MAP推定

MAP = **M**ximum **A** **P**osteriori: 最大事後確率推定\
(最尤推定は **M**aximum **L**ikelihood)

尤度ではなく事後確率を最大化するパラメータを見つける。

***

パラメータ$\mathrm{w}$自体が分布を持つと考え、その分布のパラメータ(**ハイパーパラメータ**)を$\alpha$とする。\
パラメータ$\mathrm{w}$の事前確率と事後確率に関するベイズの定理は、

$$
p(\mathrm{w} | \mathrm{x}, \mathrm{t}, \beta) \propto p(\mathrm{t} | \mathrm{x}, \mathrm{w}, \beta) p(\mathrm{w})\\
\rightarrow p(\mathrm{w} | \mathrm{x}, \mathrm{t}, \beta, \alpha) \propto p(\mathrm{t} | \mathrm{x}, \mathrm{w}, \beta) p(\mathrm{w} | \alpha)
$$

... (1.67)は一体なんだ？$\exp$の外側はどこに消えた？

### 1.2.7 ベイズ曲線フィッティング


