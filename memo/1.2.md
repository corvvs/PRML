## 1.2 確率論

#### 問題設定

- 赤と青の箱がある。
- 赤の箱にはリンゴとオレンジがそれぞれ2個,6個入っている。
- 青の箱にはリンゴとオレンジがそれぞれ3個,1個入っている。
- まず箱を1つ選び、選んだ箱からさらに果物を1つ選ぶ。
- 箱の選び方は、赤が選ばれる確率 : 青が選ばれる確率 = 4:6 となるように選ぶ。
- 果物の選び方は一様。

#### 問題: 選ばれた果物がオレンジだった時、選んだ箱が赤/青である確率は？

- ベイズの定理: `P(X|Y) * P(Y) = P(X,Y) = P(Y|X) * P(X)`
  - よって、`P(X|Y) = P(Y|X) P(X) / P(Y)`
- `P(赤) = 2/5, P(青)  = 3/5`
- `P(オレンジ|赤) = 3/4, P(オレンジ|青) = 1/4`
- `P(オレンジ, 赤) = 6/20, P(オレンジ, 青) = 3/20`
- `P(オレンジ) = 9/20`
- `P(赤|オレンジ) = P(赤, オレンジ) / P(オレンジ) = (6/20) / (9/20) = 2/3`
- `P(青|オレンジ) = P(青, オレンジ) / P(オレンジ) = (3/20) / (9/20) = 1/3`

### 1.2.2

Markdown Math のテスト。

$$
\mathbb{E}[f] =  \sum_x p(x)f(x) \\
\mathbb{E}[f] =  \int dx p(x)f(x) \\
var[f] = \mathbb{E}[ (f(x) - \mathbb{E}[f])^2 ] \\
= \sum_x p(x) \left( f(x) - \mathbb{E}[f] \right)^2 \\
= \sum_x p(x) \left( f(x) - \sum_x p(x)f(x) \right)^2 \\
= \sum_x p(x) \left( f(x)^2 - 2f(x)\sum_x p(x)f(x) + \left(\sum_x p(x)f(x)\right)^2 \right)\\
= \left( \sum_x p(x)f(x)^2 \right) - 2\left(\sum_x p(x)f(x)\right)\left(\sum_x p(x)f(x)\right) + \left( \sum_x p(x)\right)\left(\sum_x p(x)f(x)\right)^2\\
= \left( \sum_x p(x)f(x)^2 \right) - 2\left(\sum_x p(x)f(x)\right)^2 + \left(\sum_x p(x)f(x)\right)^2\\
= \left( \sum_x p(x)f(x)^2 \right) - \left(\sum_x p(x)f(x)\right)^2\\
= \mathbb{E}[f^2] - \mathbb{E}[f]^2
$$

#### 共分散

$$
\rm{cov}[x,y] = \mathbb{E}_{x,y}[\left(x - \mathbb{E}[x]\right)\left(y - \mathbb{E}[y]\right)]
$$

特に

$$
\rm{cov}[x,x] = \rm{var}[x].
$$

$$
\mathbb{E}_{x,y}[\left(x - \mathbb{E}[x]\right)\left(y - \mathbb{E}[y]\right)]\\
= \sum_{x,y}p(x,y)\left(x - \mathbb{E}[x]\right)\left(y - \mathbb{E}[y]\right)\\
= \sum_{x,y}p(x,y)\left(xy - y\mathbb{E}[x] - x\mathbb{E}[y] + \mathbb{E}[x]\mathbb{E}[y]\right)\\
= \sum_{x,y}p(x,y)xy - \mathbb{E}[x]\sum_{x,y}p(x,y)y - \mathbb{E}[y]\sum_{x,y}p(x,y)x + \mathbb{E}[x]\mathbb{E}[y]\\
= \sum_{x,y}p(x,y)xy - \mathbb{E}[x]\sum_yp(y)y - \mathbb{E}[y]\sum_xp(x)x + \mathbb{E}[x]\mathbb{E}[y]\\
= \sum_{x,y}p(x,y)xy - \mathbb{E}[x]\mathbb{E}[y] - \mathbb{E}[y]\mathbb{E}[x] + \mathbb{E}[x]\mathbb{E}[y]\\
= \sum_{x,y}p(x,y)xy - \mathbb{E}[x]\mathbb{E}[y]\\
= \mathbb{E}_{x,y}[xy] - \mathbb{E}[x]\mathbb{E}[y]
$$


もし、

$$
\sum_{x,y}p(x,y)xy = \sum_{x,y}(x)p(y)xy = \left(\sum_xp(x)x\right)\left(\sum_yp(y)y\right)
$$

と書けるなら、$\rm{cov}[x,y] = 0$.\
$p(x,y) = p(x)p(y)$と書けることは$x,y$が独立であることに他ならない(演習1.6)。

### 1.2.3 ベイズ確率

- パラメータベクトル: $\bm{w}$
- データ: $\mathcal{D}$
  - 本文中の書体は筆記体: `$\mathcal{D}$`
- パラメータベクトルの事前確率: $p(\bm{w})$
- データが観測されたデータになる確率: $p\mathcal{D})$
- パラメータ$\bm{w}$のもとでのデータの実現確率 = 尤度関数: $p(\mathcal{D} | \bm{w})$
  - 確率変数は$\mathcal{D}$なので、$\bm{w}$による積分は意味を持たない。
  - **最尤推定**: 尤度関数$p(\mathcal{D} | \bm{w})$を最大にするパラメータベクトル$\bm{w}$を結果とする。
  - (機械学習業界における)誤差関数: $-\log p(\mathcal{D} | \bm{w})$
    - 尤度関数の最大化 <=> 誤差関数の最小化
- データ$\mathcal{D}$のもとでのパラメータベクトルの実現確率 = 事後確率: $p(\bm{w} | \mathcal{D}) = p(\mathcal{D} | \bm{w}) p(\bm{w}) / p(\mathcal{D})$

事後確率$p(\bm{w} | \mathcal{D})$の確率変数は$\bm{w}$なので、$\bm{w}$による積分値(連続分布の場合)は1になるはず。よって、

$$
\int \frac{p(\mathcal{D} | \bm{w}) p(\bm{w})} {p(\mathcal{D})}d\bm{w}\\
= \frac{\int p(\mathcal{D} | \bm{w}) p(\bm{w}) d\bm{w} } {p(\mathcal{D})} = 1.\\
\rightarrow \int p(\mathcal{D} | \bm{w}) p(\bm{w}) d\bm{w} = p(\mathcal{D}).
$$

となるはず。

重要そうな引用:

> ベイズ法を完全に実行するには特に全パラメータ空間での周辺化（和または積分）を必要としたからである。\
> これらの操作は後から見るように、予測を行ったり、異なるモデルを比較したりするために必要なものである。

### 1.2.4 ガウス分布

$(\infty,+\infty)$上の連続な分布関数。

$$
\mathcal{N}(x | \mu,\sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}}\exp\left(-\frac{1}{2\sigma^2}(x-\mu)^2\right).
$$

#### 規格化

$$
\int^{+\infty}_{-\infty}\mathcal{N}(x | \mu,\sigma^2)dx
= \int^{+\infty}_{-\infty}\mathcal{N}(x | 0 ,\sigma^2)dx
= \int^{+\infty}_{-\infty}\mathcal{N}(x | 0 ,1)dx \\
= \int^{+\infty}_{-\infty} \frac{1}{\sqrt{2\pi}}\exp\left(-x^2/2\right)dx
$$

$x$と独立な変数$y$に対する正規分布を考え、2つの正規分布の積を求めることにすると、

$$
\int^{+\infty}_{-\infty}\mathcal{N}(x | \mu,\sigma^2)dx \int^{+\infty}_{-\infty}\mathcal{N}(y | \mu,\sigma^2)dy\\
= \int^{+\infty}_{-\infty} \frac{1}{\sqrt{2\pi}}\exp\left(-x^2/2\right)dx
\int^{+\infty}_{-\infty} \frac{1}{\sqrt{2\pi}}\exp\left(-y^2/2\right)dy \\
= \int^{+\infty}_{-\infty}\int^{+\infty}_{-\infty}dxdy \frac{1}{2\pi}\exp\left(-(x^2+y^2)/2\right)
$$

この積分を極座標に変換すると、

$$
\int^{+\infty}_{-\infty}\int^{+\infty}_{-\infty}dxdy \frac{1}{2\pi}\exp\left(-(x^2+y^2)/2\right)\\
= \int^{+\infty}_{0}dr\int^{+\pi}_{-\pi}\phi \frac{r}{2\pi}\exp\left(-r^2/2\right)\\
= \int^{+\infty}_{0}dr r\exp\left(-r^2/2\right)
$$

ここで、

$$
\frac{d}{dr}\exp\left(-r^2/2\right) = -r\exp\left(-r^2/2\right)
$$

であることを考慮すると、

$$
\int^{+\infty}_{0}dr r\exp\left(-r^2/2\right) = \left[-\exp\left(-r^2/2\right)\right]^{+\infty}_{0} = \exp(0) - 0 = 1.
$$

(演習1.7)

#### 期待値

$$
-\sigma^2\frac{d}{dx}\exp\left(-\frac{1}{2\sigma^2}x^2\right) = x\exp\left(-\frac{1}{2\sigma^2}x^2\right)
$$

であることを考えると、

$$
\int^{+\infty}_{-\infty}x \frac{1}{\sqrt{2\pi\sigma^2}}\exp(-\frac{1}{2\sigma^2}(x-\mu)^2)\\
= \int^{+\infty}_{-\infty}(x+\mu) \frac{1}{\sqrt{2\pi\sigma^2}}\exp(-\frac{1}{2\sigma^2}x^2) \\
= \int^{+\infty}_{-\infty}x\frac{1}{\sqrt{2\pi\sigma^2}}\exp(-\frac{1}{2\sigma^2}x^2)
+ \int^{+\infty}_{-\infty}\mu\frac{1}{\sqrt{2\pi\sigma^2}}\exp(-\frac{1}{2\sigma^2}x^2)\\
= \left[-\sigma^2\exp(-\frac{1}{2\sigma^2}x^2)\right]^{+\infty}_{-\infty} + \mu = (0 - 0) + \mu = \mu.
$$

#### 分散

$$
\int^{+\infty}_{-\infty}(x-\mu)^2 \frac{1}{\sqrt{2\pi\sigma^2}}\exp\left(-\frac{1}{2\sigma^2}(x-\mu)^2\right)dx\\
=  \int^{+\infty}_{-\infty}x^2 \frac{1}{\sqrt{2\pi\sigma^2}}\exp\left(-\frac{1}{2\sigma^2}x^2\right)dx\\.
$$

ここで、

$$
-\sigma^2\frac{d^2}{dx^2}\exp\left(-\frac{1}{2\sigma^2}x^2\right) = \frac{d}{dx} x\exp\left(-\frac{1}{2\sigma^2}x^2\right)\\
= \exp\left(-\frac{1}{2\sigma^2}x^2\right) - \frac{x^2}{\sigma^2}\exp\left(-\frac{1}{2\sigma^2}x^2\right)\\
\rightarrow 
-\sigma^2\frac{d}{dx}x\exp\left(-\frac{1}{2\sigma^2}x^2\right) + \sigma^2\exp\left(-\frac{1}{2\sigma^2}x^2\right) = x^2\exp\left(-\frac{1}{2\sigma^2}x^2\right)\\
$$

から、

$$
\int^{+\infty}_{-\infty}x^2 \frac{1}{\sqrt{2\pi\sigma^2}}\exp\left(-\frac{1}{2\sigma^2}x^2\right)\\
= \int^{+\infty}_{-\infty}\sigma^2\frac{1}{\sqrt{2\pi\sigma^2}}\exp\left(-\frac{1}{2\sigma^2}x^2\right) - \sigma^2 \left[x\exp\left(-\frac{1}{2\sigma^2}x^2\right)\right]^{+\infty}_{-\infty}\\
= \sigma^2.
$$


#### モード

分布関数$f(x)$の最大値を与える$x$の値のこと(argmax)。

明らかに $\argmax \mathcal{N}(x | \mu, \sigma^2) = \mu.$

#### 多変量ガウス分布

$$
\mathcal{N}(\mathrm{x} | \mathrm{\mu}, \mathrm{\Sigma}) = \frac{1}{(2\pi)^{D/2}}\frac{1}{|\mathrm{\Sigma}|^{1/2}}\exp\left( -\frac{1}{2}(\mathrm{x} - \mathrm{\mu})^\mathrm{T} \mathrm{\Sigma}^{-1} (\mathrm{x} - \mathrm{\mu}) \right)
$$

- $D$: 次元
- $\mathrm{x}$: $D$次元の連続変数ベクトル
- $\mathrm{\mu}$: $D$次元の平均ベクトル
- $\mathrm{\Sigma}$: $D \times D$次元の共分散行列
- $|\mathrm{\Sigma}|$: 共分散行列の行列式


(疑問) $\exp$内の$\mathrm{\Sigma}$はなぜ逆行列？

